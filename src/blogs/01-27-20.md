## Testing Computer Vision

While the drone is under construction, the computer vision stack needed to be worked on. The team decided to purchase an additional wireless camera for testing. A test rig was built for the camera as shown below:

![Camera Testing Rig](https://i.imgur.com/nUKmbLW.png)

The camera setup uses the same wifi receiver as the one on the drone and is externally powered via 3 AAA batteries. A video of it working is shown here:

[![Camera Setup](https://i.imgur.com/0u2kLMt.png)](https://drive.google.com/file/d/112zd1EL5FNK65ZS7u-e_gHLZHRamBm-z/view "Camera Setup")

## Simulating the Drone with ROS

Due to the complexity of performing offboard control with a quadcopter, it was decided to develop the software within a simulator before testing on the actual device. The Pixhawk platform has many software integrations with ROS that are already developed as shown [here](http://dev.px4.io/master/en/index.html). 

To fully understand how ROS works with the Pixhawk software stack, let’s take a look at the communication with [QGroundControl](http://qgroundcontrol.com/), a software used to configure Pixhawk drones and to gather telemetry data. Essentially, QGroundControl communicates via MAVLink messages which are sent to the drone through radio signals. The drone radio receives the signals and converts them into commands that the drone can command. An high level flow of communication is shown below:

![Flow of Communication](https://i.imgur.com/l27Nd3k.png)

With ROS, we extend QGroundStation control with additional information, allowing us to create more complex drone behaviour. An example flow with ROS would like as follows:

![Extended Flow of Communication](https://i.imgur.com/KDJpbB4.png)

The Pixhawk is a very active software platform with continuous updates and the documentation was a bit convoluted to fully understand. After many attempts to setup the whole system, a “getting started” manual was created to streamline the development process, shown [here](https://github.com/jwang61/Bee-Boys).

Once the steps are followed, a working simulation in Gazebo could be controlled as shown below:

![Drone Simulation in Gazebo](https://i.imgur.com/CwVlOnQ.png)

Here, ROS is outputting commands to the drone which is being fed to the drone simulation. The drone is hovering 2 m off the ground.
